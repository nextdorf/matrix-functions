%\documentclass{article}
\documentclass[12pt]{article}

\usepackage[a4paper, total={185mm, 265mm}]{geometry} %A4: 210px * 297px

\usepackage[utf8]{inputenc} % Required for inputting international characters
\usepackage{babel}
\usepackage[T1]{fontenc} % Output font encoding for international characters

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{bbm}
%\usepackage{mathpazo} % Use the Palatino font by default
%\usepackage{pazocal}
\usepackage{mathtools}
\usepackage{physics}

\usepackage{xcolor}
\usepackage{subcaption}
\usepackage{float}
\usepackage{shellesc}
\usepackage{svg}
\usepackage{comment}
\usepackage[linkcolor=blue, colorlinks=true]{hyperref}

\usepackage[backend=bibtex,style=authoryear,natbib=true]{biblatex} % Use the bibtex backend with the authoryear citation style (which resembles APA)

\addbibresource{literature.bib} % The filename of the bibliography

\usepackage[autostyle=true]{csquotes} % Required to generate language-dependent quotes in the bibliography
\usepackage{color}


\newcommand{\argmin}{\operatornamewithlimits{argmin}}
\newcommand{\argmax}{\operatornamewithlimits{argmax}}
\renewcommand{\i}{{i\mkern1mu}}
\newcommand{\del}{\partial}
\newcommand{\cev}[1]{\reflectbox{\ensuremath{\vec{\reflectbox{\ensuremath{#1}}}}}}

\newcommand{\pushright}[1]{\ifmeasuring@#1\else\omit\hfill$\displaystyle#1$\fi\ignorespaces}
\newcommand{\pushleft}[1]{\ifmeasuring@#1\else\omit$\displaystyle#1$\hfill\fi\ignorespaces}

\begin{document}



\centerline{\sc \large Documentation for Matrixfuncs}
\vspace{.5pc}
\vspace{2pc}

\tableofcontents

\section{Mathematical background}
\subsection{2 dimensional case}
The Cayley-Hamilton theorem states for $A\in \mathbb C^{n\times n}:\ p_A(A)=0$\\
For $n=2$:
\begin{align}
p_A(\lambda) =& \det(\lambda\mathbbm 1 - A) = (\lambda - \lambda_1)(\lambda - \lambda_2) = \lambda^2 -\lambda\tr A + \det A\\
\Rightarrow A^2 =& A \tr A - \mathbbm 1 \det A
\end{align}
So $A^2$ is a linear combination of $A$ and $\mathbbm 1$. By complete induction it follows that $A^n$ is also such a linear combination of $A$ and $\mathbbm 1$ for any $n \in \mathbbm N_0$:
\begin{align}
A^n \eqqcolon a_n A + b_n\mathbbm 1,\ \ \ A^{n+1} = \big(a_n\tr A + b_n\big)A - \big(a_n\det A \big)\mathbbm 1
\end{align}
\begin{align}
a_{n+1} = a_n\tr A + b_n,\ b_{n+1} = -a_n\det A,\ a_0=0,\ a_1=1,\ b_0=1,\ b_1=0 \label{recurrent 2dim}
\end{align}
In order to solve the recurrence equation we use a shifting operator $\Delta$ for $a_n$, s.t. $a_{n+1} = \Delta a_n$
\begin{align}
0 = \big(\Delta^2 - \Delta\tr A + \det A\big) a_n = p_A(\Delta) a_n = (\Delta-\lambda_1)(\Delta-\lambda_2) a_n
\end{align}
As ansatz we choose $a_n$ as a linear combination of the solutions of $0=(\Delta-\lambda_1)a_n$ and $0=(\Delta-\lambda_2)a_n$. In general this ansatz only works if $\lambda_1 \neq \lambda_2$. We will consider the case $\lambda_1 = \lambda_2$ again in the end of this section and in section $\ref{ch:math.general case}$:
\begin{align}
a_n =& c_1 \lambda_1^n + c_2\lambda_2^n
\end{align}
As induction start we can simply consider the trivial cases $n=0$ and $n=1$:
\begin{align}
a_0 =& c_1 + c_2 = 0,\ a_1 = c_1\lambda_1 + c_2\lambda_2 = 1 \nonumber\\
\Rightarrow c_2 =& -c_1,\ c_1(\lambda_1 - \lambda_2) = 1 \nonumber\\
\Rightarrow c_1 =& -c_2 = \frac 1 {\lambda_1 - \lambda_2}
\end{align}
We found the solutions for $a_n$:
\begin{align}
a_n = \frac {\lambda_1^n - \lambda_2^n}{\lambda_1 - \lambda_2},\ b_n \overset{\eqref{recurrent 2dim}}=-\frac {\lambda_2\lambda_1^n - \lambda_1\lambda_2^n}{\lambda_1 - \lambda_2}
\end{align}
and thereby the linear combination of $A^n$:
\begin{align}
A^n =& \frac {\lambda_1^n - \lambda_2^n}{\lambda_1 - \lambda_2} A - \frac {\lambda_2\lambda_1^n - \lambda_1\lambda_2^n}{\lambda_1 - \lambda_2} \mathbbm 1
\end{align}
Since $A^n$ is linear in $\lambda_i^n$ we know how to evaluate arbitrary polynomials of $A$ in the krylov space. Let $q(x)$ be a polynomial:
\begin{align}
q(A) =& \frac 1{\lambda_1 - \lambda_2} \left[(q(\lambda_1) - q(\lambda_2))A - (\lambda_2 q(\lambda_1) - \lambda_1 q(\lambda_2)) \mathbbm 1\right]
\end{align}
Since the coefficients only depend on $p(\lambda_i)$ the formula can be generalized to all functions which are analytical in $\lambda_1$ and $\lambda_2$. Let $f(x)$ be a analytical in the eigenvalues of $A$:
\begin{align}
f(A) =& \frac 1{\lambda_1 - \lambda_2} \left[(f(\lambda_1) - f(\lambda_2))A - (\lambda_2 f(\lambda_1) - \lambda_1 f(\lambda_2)) \mathbbm 1\right] \label{func 2dim}
\end{align}
The generalization of $\eqref{func 2dim}$ is the core of this package. The important properties are that it yields the result to arbitrary precision in constant time and that the application of $f$ commutes with any linear function applied to the krylov space. With other words this means there exists a rank-3 tensor $F$, which only depends on $A$, s.t. $f(A)_{ij} = F_{ijk} f(\lambda_k)$.\\
Since $f(A)$ is continuous in the eigenvalues and the set of square matrices with unequal eigenvalues is dense in the set of all square matrices, we can just consider the limit of $\lambda_1 \to \lambda_2$ to calculate the case $\lambda_1 = \lambda_2$:
\begin{align}
f(A|\lambda_1&=\lambda+\epsilon,\; \lambda_2 = \lambda) = \frac 1\epsilon \left[ \epsilon f'(\lambda) A - \epsilon(\lambda f'(\lambda) - f(\lambda))\mathbbm 1 \right] + o(\epsilon) \nonumber\\
\overset{\epsilon\to 0}{\longrightarrow}& f'(\lambda)\big( A-\lambda \mathbbm 1 \big) + f(\lambda)\mathbbm 1\nonumber\\
\Rightarrow f(A) =& f'(\lambda)\big( A-\lambda \mathbbm 1 \big) + f(\lambda)\mathbbm 1\ \ \text{if $\lambda$ is the only eigenvalue of $A$}  \label{func 2dim 1eigval}
\end{align}
So when $A$ is not diagonalizable $f(A)$ depends on $f'(\lambda)$. In general we will find that $f(A)$ depends on $f(\lambda_i), f'(\lambda_i), \dots, f^{(m)}(\lambda_i)$ where $m$ is the difference of the algebraic and geometric multiplicity of $\lambda_i$.
\subsection{Example for 2 dimensions: $\sin x$}
There are many applications and possible use cases for matrix functions, but the main application this package is written for are difference equations. Assuming you want to consider a sequence of vectors $(v_i)_{i=0}^\infty \subset \mathbbm K^n$ which satisfies $v_{i+1} = M v_i$ for some matrix $M\in \mathbbm K^{n\times n}$. An obvious conclusion is $v_k = M^k v_0$. With $\eqref{func 2dim}$ or $\eqref{func 2dim 1eigval}$ we can express $M^k$ without any matrix multiplications. Instead with just apply $f(\lambda) = \lambda^k$ to all eigenvalues. We even can apply $v_0$ or any other tensor contraction to $f(M)$ before we specify $k$. Calculating this things beforehand can speedup the total calculation if we need to calculate $v_k$ for many different $k$.\\
Another neat application is the analytical continuation of $v_k$ in $k$ by setting $f(\lambda) = e^{k \ln(\lambda)}$. We will use this in the example here by solving a difference equation for a sampled $\sin$ function and then evaluating the numerically solved $\sin$ between the sampled points.\\
Consider the sum identity of $\sin$:
\begin{align}
\sin(x+a) = \sin(x)\cos(a) + \cos(x)\sin(a) \label{sin(a+b)}
\end{align}
For fixed $a$ $\sin(x+a)$ can be expressed as a linear combination of the basis $\sin x$ and $\cos b$. Therefore $\sin x$ can be written as a linear combination of $\sin(x+a)$ and $\sin(x+2a)$ for almost all $a$:
\begin{align}
\sin(x) \eqqcolon& \alpha\sin(x+a) + \beta\sin(x+2a) \nonumber\\
=& \alpha\big(\sin(x)\cos(a) + \sin(a)\cos(x)\big) + \beta\big(\sin(x)\cos(2a) + \sin(2a)\cos(x)\big) \nonumber\\
=& \sin x\big( \alpha\cos a + \beta\cos(2a) \big) + \cos x\big( \alpha\sin a + \beta\sin(2a) \big) \\
\Rightarrow \begin{pmatrix} 1 \\ 0 \end{pmatrix} =& \begin{pmatrix} \cos a & \cos(2a) \\ \sin a & \sin(2a) \end{pmatrix} \begin{pmatrix} \alpha \\ \beta \end{pmatrix}\\
\begin{pmatrix} \alpha \\ \beta \end{pmatrix} =& \begin{pmatrix} \cos a & \cos(2a) \\ \sin a & \sin(2a) \end{pmatrix}^{-1} \begin{pmatrix} 1 \\ 0 \end{pmatrix} \nonumber\\
=& \frac 1{\cos a\sin(2a) - \sin a\cos(2a)} \begin{pmatrix} \sin(2a) & -\cos(2a) \\ -\sin a & \cos a \end{pmatrix} \begin{pmatrix} 1 \\ 0 \end{pmatrix} \nonumber\\
=& \frac 1{\sin a} \begin{pmatrix} \sin(2a) \\ -\sin a \end{pmatrix} \nonumber\\
\overset{\eqref{sin(a+b)}}=& \begin{pmatrix} 2\cos(a) \\ -1 \end{pmatrix} \nonumber
\end{align}
From this we can construct a difference equation which shifts $\sin$ by $a$. 
\begin{align}
\begin{pmatrix} \sin x \\ \sin(x - a) \end{pmatrix} =& \underbrace{\begin{pmatrix} 2\cos a & -1 \\ 1 & 0 \end{pmatrix}}_{\eqqcolon M(a)} \begin{pmatrix} \sin (x-a) \\ \sin(x-2a) \end{pmatrix} \nonumber\\
\Rightarrow \begin{pmatrix} \sin (x+na) \\ \sin(x+(n-1)a) \end{pmatrix} =& M(a)^n \begin{pmatrix} \sin x \\ \sin(x-a) \end{pmatrix}\\
\Rightarrow \sin(x+na) =& \hat e_1 \cdot M(a)^n \begin{pmatrix} \sin x \\ \sin(x-a) \end{pmatrix}\\
\Rightarrow \sin(x+y) =& \hat e_1 \cdot e^{\frac ya \ln(M(a))} \begin{pmatrix} \sin x \\ \sin(x-a) \end{pmatrix}
\end{align}
We can now use the formula for two dimensions $\eqref{func 2dim}$ in order to solve for $\sin(x+y)$:
\begin{align}
\sin(x+y) \overset{\eqref{func 2dim}}=& \hat e_1 \cdot \frac 1{\lambda_1 - \lambda_2} \left[(f(\lambda_1) - f(\lambda_2))M(a) - (\lambda_2 f(\lambda_1) - \lambda_1 f(\lambda_2)) \mathbbm 1\right] \begin{pmatrix} \sin x \\ \sin(x-a) \end{pmatrix} \label{sin(x+y) numerical}
\end{align}
\begin{align*}
\text{with}\ f(\lambda) =& e^{\frac ya \ln\lambda}\\
\lambda_{1,2} =& \frac 12\tr M(a) \pm \sqrt{\big(\frac 12\tr (M(a))\big)^2 - \det(M(a))}\nonumber\\
=& \cos a \pm \sqrt{\cos^2 a - 1}\nonumber\\
=& e^{\pm \i a}\\
f(\lambda_{1,2}) =& e^{\pm \i y}
\end{align*}
Simplifying $\eqref{sin(x+y) numerical}$ will yield $\eqref{sin(a+b)}$.
\subsection{General case}\label{ch:math.general case}
Similarly to the 2d-case we use the Cayley-Hamilton-theorem: $A \in \mathbb C^{n\times n},\ p_A(A) = 0$
\begin{align}
p_A(\lambda) =& \det(\lambda\mathbbm 1 - A) = \prod_{k=1}^n(\lambda - \lambda_k) \eqqcolon \lambda^n - \sum_{k=0}^{n-1} \Lambda_k \lambda^k\nonumber\\
\Rightarrow \Lambda_k =& \sum_{\substack{j_1,\dots,j_{n-k} = 1,\\ j_1<\dots<j_{n-k}}}^n (-1)^{n-k+1} \prod_{i=1}^{n-k} \lambda_{j_i} \\
A^n =& \sum_{k=0}^{n-1} \Lambda_k A^k\nonumber\\
A^m \eqqcolon& \sum_{k=0}^{n-1} \alpha_{mk} A^k\\
A^{m+1} =& \sum_{k=1}^{n-1} (\alpha_{m,k-1} + \alpha_{m,n-1}\Lambda_k) A^k + \alpha_{m,n-1}\Lambda_0 A^0 \nonumber\\
\Rightarrow \alpha_{m+1,0} =& \alpha_{m,n-1} \Lambda_0,\ \alpha_{m+1,k} = \alpha_{m,k-1} + \alpha_{m,n-1}\Lambda_k \label{recurrent ndim}
\end{align}
The recurrence equation $\eqref{recurrent ndim}$ can be solved by noticing that all $\alpha_{m,n-1}$ can be reduced to a function of $\alpha_{m-1,n-1},\; \alpha_{m-2,n-1}\; \dots$
\begin{align}
\alpha_{m,n-1} =& \sum_{k=1}^{n-1} \alpha_{m-k,n-1}\Lambda_{n-k} + \alpha_{m+1-n,0} \nonumber\\
=& \sum_{k=1}^n \alpha_{m-k,n-1}\Lambda_{n-k} \nonumber\\
=& \sum_{k=0}^{n-1} \alpha_{m+k-n,n-1}\Lambda_k \nonumber\\
\Rightarrow 0=& \alpha_{m+n,n-1} - \sum_{k=0}^{n-1} \alpha_{m+k,n-1}\Lambda_k \nonumber\\
=& \big( \Delta^n - \sum_{k=0}^{n-1} \Delta^k \Lambda_k \big) \alpha_{m, n-1} \ \ \ \text{with}\ \Delta \alpha_{mk} = \alpha_{m+1,k}\nonumber\\
=& p_A(\Delta) \alpha_{m, n-1}\nonumber\\
=& \prod_{k=1}^r\big( \Delta - \lambda_k \big)^{\mu_k}\ \alpha_{m, n-1}\\
&\ \ \text{with $\mu_k$ being the algebraic multiplicity of $\lambda_k$}\nonumber
\end{align}
The general solution is $\alpha_{m, n-1} = \sum_{k=1}^r \lambda_k^m p_k(m)$ with $p_k$ being an arbitrary polynomial of degree $\mu_k-1$. Proof:
\begin{align*}
\text{Induction start: } 0 = \big( \Delta - \lambda \big) c_n\ \Rightarrow\ c_n = \lambda c_{n-1} = \lambda^n c_0
\end{align*}
\begin{align*}
\text{Assume } 0 =& \big( \Delta - \lambda \big)^m \lambda^n \sum_{k=0}^{m-1} c_k n^k \ \forall c_0, \dots, c_{m-1}\\
\Rightarrow \big( \Delta - \lambda \big)^{m+1} &\lambda^n \sum_{k=0}^m c_k n^k = \big( \Delta - \lambda \big)^m \big( \Delta - \lambda \big) \lambda^n c_m n^m + \big( \Delta - \lambda \big) \big( \Delta - \lambda \big)^m \lambda^n \sum_{k=0}^{m-1} c_k n^k\\
=& \big( \Delta - \lambda \big)^m \big( (n+1)^m - n^m \big) \lambda^{n+1} c_m \\
=& \big( \Delta - \lambda \big)^m \lambda^n \sum_{k=0}^{m-1} \binom mk \lambda c_m n^k\\
=& 0\\
\Rightarrow 0 =& \big( \Delta - \lambda \big)^m \lambda^n \sum_{k=0}^{m'} c_k n^k \ \forall c_0, \dots, c_{m'-1},\; m>m'
\end{align*}
\begin{align*}
\text{Now consider } \bar c_n = \big(\Delta - \lambda\big) c_n\ \Rightarrow\ c_{n+1} = \bar c_n + \lambda c_n = \sum_{k=0}^n \lambda^k \bar c_{n-k} + \lambda^{n+1} c_0
\end{align*}
Since the solution of $c_n$ is linear in $\bar c_n$ we can consider the dimension of the solution space if $\bar c_n$ is itself a solution of a similar equation. The solution space of $0 = \big(\Delta - \lambda_1\big) c_n^{(1)}$ is 1-dimensional. Therefore the solution space of $c_n^{(m)} = \big(\Delta - \lambda_1\big) c_n^{(m+1)}$ is either of the same dimension as the solution space of $c_n^{(m)}$ or the dimension increases by 1. So the dimension of the solution space of $p_A(\Delta) \alpha_{m, n-1}$ is at most $n$. Since $\sum_{k=1}^r \lambda_k^m p_k(m)$ is a $\sum_{k=1}^r \dim(p_k) = n$ dimensional solution it is the general solution.\\
\null\hfill$\Box$
\begin{align}
\alpha_{m,n-1} =& \sum_{k=1}^r \sum_{l=0}^{\min(\mu_k-1,m)} \bar\beta_{kl} \lambda_k^{m-l} \frac{m!}{(m-l)!} = \sum_{k=1}^r \sum_{l=0}^{\mu_k-1} \bar\beta_{kl} \left. \del_\lambda^l \lambda^m \right|_{\lambda = \lambda_k} \eqqcolon \sum_{k=1}^n \beta_k \lambda_k^{(m)}\\
\beta_k =& (\bar\beta_{1,0}, \dots, \bar\beta_{1,\mu_1-1},\; \bar\beta_{2,0}, \dots, \bar\beta_{2,\mu_2-1},\; \dots,\; \bar\beta_{r,0}, \dots, \bar\beta_{r,\mu_r-1})_k \nonumber\\
\lambda_k^{(m)} =& (\lambda_1^m, \dots, \del_{\lambda_1}^{\mu_1-1} \lambda_1^m,\; \lambda_2^m, \dots, \del_{\lambda_2}^{\mu_2-1} \lambda_2^m,\; \dots,\; \lambda_r^m, \dots, \del_{\lambda_r}^{\mu_r-1} \lambda_r^m)_k \nonumber
\end{align}
For $m<n:\ \alpha_{mk} = \delta_{mk}\ \Rightarrow \delta_{m,n-1} = \beta_k \lambda_k^{(m)}$
\begin{align}
\Rightarrow \vec \beta \perp& \sum_{k=1}^n \hat e_k \lambda_k^m \eqqcolon \vec \lambda^{(m)} \ \text{for}\ m=0\dots n-2 \nonumber\\
\tilde\beta_k \coloneqq& \det(\hat e_k | \vec\lambda^{(n-2)} | \vec\lambda^{(n-3)} | \dots | \vec\lambda^{(0)})\nonumber\\
\beta =& \tilde\beta /\big( \tilde \beta \cdot \lambda^{(n-1)} \big)
\end{align}
$\eqref{recurrent ndim}$ yields for $\alpha_{mk}$:
\begin{align}
\alpha_{mk} =& \sum_{j=1}^{k+1} \alpha_{m-j,n-1} \Lambda_{k+1-j} = \sum_{j=1}^{k+1} \vec\beta\cdot\vec\lambda^{(m-j)} \Lambda_{k+1-j}
\end{align}
As in the two dimensional case this defines $f(A)$ if $f$ is analytical in the eigenvalues of $A$. If none of the eigenvalues is $0$:
\begin{align}
A^m =& \sum_{k=0}^{n-1} A^k \sum_{j=1}^{k+1} \Lambda_{k+1-j} \sum_{l=1}^r \sum_{p=0}^{\min(\mu_l-1,m-j)} \bar\beta_{lp} \lambda_l^{m-j-p} \frac{(m-j)!}{(m-j-p)!}\\
f(A) =& \sum_{k=0}^{n-1} A^k \sum_{j=1}^{k+1} \Lambda_{k+1-j} \sum_{l=1}^r \sum_{p=0}^{\mu_l-1} \bar\beta_{lp} \del_{\lambda_l}^p \lambda_l^{-j} f(\lambda_l) \nonumber\\
=& \sum_{k=0}^{n-1} A^k \sum_{j=1}^{k+1} \Lambda_{k+1-j} \sum_{l=1}^r \sum_{p=0}^{\mu_l-1} \bar\beta_{lp} \sum_{q=0}^p \binom pq (-1)^{p-q}\frac{(j-1+p-q)!}{(j-1)!} \lambda_l^{-j-p+q} f^{(q)}(\lambda_l)
\end{align}
Since $f(A)$ is linear in $A^k$ and $f^{(q)}(\lambda_l)$ we can define the tensors $\mathcal F$ and $F$, s.t.
\begin{align}
f(A) = \sum_{i=0}^{n-1} \sum_{j=1}^r \sum_{k=0}^{\mu_j-1} \mathcal F_{ij}^{(k)} A^i f^{(k)}(\lambda_j),\ \ \ \ F_{ijk}^{(l)} = \sum_{m=0}^{n-1} \mathcal F_{mk}^{(l)} (A^m)_{ij}
\end{align}
\begin{align}
\mathcal F_{kl}^{(q)} =& \del_{x_q} \del_{y_l} \sum_{j=1}^{k+1} \Lambda_{k+1-j} \sum_{l'=1}^r \sum_{p=0}^{\mu_{l'}-1} \bar\beta_{l'p} \sum_{q'=0}^p \binom p{q'} (-1)^{p-q'}\frac{(j-1+p-q')!}{(j-1)!} \lambda_{l'}^{-j-p+q'} x_{q'} y_{l'} \nonumber\\
=& \sum_{j=1}^{k+1} \Lambda_{k+1-j} \sum_{p=q}^{\mu_l-1} \bar\beta_{lp} \binom pq (-1)^{p-q}\frac{(j-1+p-q)!}{(j-1)!} \lambda_l^{-j-p+q}
\end{align}
\subsubsection*{Sanity check for $n=2$}
\begin{itemize}
\item $\lambda_1 \neq \lambda_2\ \Rightarrow\ \mu_1 = \mu_2 = 1,\; r=2:$
\begin{align*}
\lambda_k^{(m)} =& \lambda_k^m,\ \beta_{\cdot\;0} = \frac 1{\lambda_1 - \lambda_2} \begin{pmatrix} 1\\-1 \end{pmatrix},\ \Lambda_0 = -\lambda_1\lambda_2,\ \Lambda_1 = \lambda_1 + \lambda_2\\
\mathcal F^{(0)} =& \begin{pmatrix} \Lambda_0\bar\beta_{10}/\lambda_1 & \Lambda_0\bar\beta_{20}/\lambda_2 \\ \Lambda_0\bar\beta_{10}/\lambda_1^2 + \Lambda_1\bar\beta_{10}/\lambda_1 & \Lambda_0\bar\beta_{20}/\lambda_2^2 + \Lambda_1\bar\beta_{20}/\lambda_2 \end{pmatrix} = \frac 1{\lambda_1 - \lambda_2} \begin{pmatrix} -\lambda_2 & \lambda_1 \\ 1 & -1 \end{pmatrix}\\
\Rightarrow f(A) =& \frac 1 {\lambda_1-\lambda_2}\big[ \big(f(\lambda_1) - f(\lambda_2)\big) A - \big(\lambda_2 f(\lambda_1) - \lambda_1 f(\lambda_2)\big) \mathbbm 1 \big]\ \checkmark
\end{align*}
\item $\lambda_1 = \lambda_2 = \lambda\ \Rightarrow\ \mu_1 = 2,\; r=1:$
\begin{align*}
\lambda_k^{(m)} =& \big(\lambda^m, m\lambda^{m-1}\big)_k,\ \beta_{1\;\cdot} = \begin{pmatrix} 0\\1 \end{pmatrix},\ \Lambda_0 = -\lambda^2,\ \Lambda_1 = 2\lambda\\
\mathcal F^{(0)} =& \begin{pmatrix} \Lambda_0 (\bar\beta_{10}/\lambda - \bar\beta_{11}/\lambda^2) \\ \Lambda_1 (\bar\beta_{10}/\lambda - \bar\beta_{11}/\lambda^2) + \Lambda_0 (\bar\beta_{10}/\lambda^2 - 2\bar\beta_{11}/\lambda^3) \end{pmatrix} = \begin{pmatrix} 1 \\ 0 \end{pmatrix}\\
\mathcal F^{(1)} =& \begin{pmatrix} \Lambda_0 \bar\beta_{11}/\lambda \\ \Lambda_1 \bar\beta_{11}/\lambda + \Lambda_0 \bar\beta_{11}/\lambda^2 \end{pmatrix} = \begin{pmatrix} -\lambda \\ 1 \end{pmatrix}\\
\Rightarrow f(A) =& f(\lambda)\mathbbm 1 + f'(\lambda)\big( A - \lambda\mathbbm 1 \big)\ \checkmark
\end{align*}
\end{itemize}

\begin{comment}
\begin{align}
\alpha_{m,n-1} =& \sum_{k=1}^r \lambda_k^m \sum_{l=0}^{\mu_k-1} \bar\beta_{kl} \frac{(m+l)!}{m!} = \sum_{k=1}^r \sum_{l=0}^{\mu_k-1} \bar\beta_{kl} \left. \del_\lambda^l \lambda^{m+l} \right|_{\lambda = \lambda_k} \eqqcolon \sum_{k=1}^n \beta_k \lambda_k^{(m)}\\
\beta_k =& (\bar\beta_{1,0}, \dots, \bar\beta_{1,\mu_1-1},\; \bar\beta_{2,0}, \dots, \bar\beta_{2,\mu_2-1},\; \dots,\; \bar\beta_{r,0}, \dots, \bar\beta_{r,\mu_r-1})_k \nonumber\\
\lambda_k^{(m)} =& (\lambda_1^m, \dots, \del_{\lambda_1}^{\mu_1-1} \lambda_1^{m+\mu_1-1},\; \lambda_2^m, \dots, \del_{\lambda_2}^{\mu_2-1} \lambda_2^{m+\mu_2-1},\; \dots,\; \lambda_r^m, \dots, \del_{\lambda_r}^{\mu_r-1} \lambda_r^{m+\mu_r-1})_k \nonumber
\end{align}
For $m<n:\ \alpha_{mk} = \delta_{mk}\ \Rightarrow \delta_{m,n-1} = \beta_k \lambda_k^{(m)}$
\begin{align}
\Rightarrow \vec \beta \perp& \sum_{k=1}^n \hat e_k \lambda_k^m \eqqcolon \vec \lambda^{(m)} \ \text{for}\ m=0\dots n-2 \nonumber\\
\tilde\beta_k \coloneqq& \det(\hat e_k | \vec\lambda^{(n-2)} | \vec\lambda^{(n-3)} | \dots | \vec\lambda^{(0)})\nonumber\\
\beta =& \tilde\beta /\big( \tilde \beta \cdot \lambda^{(n-1)} \big)
\end{align}
$\eqref{recurrent ndim}$ yields for $\alpha_{mk}$:
\begin{align}
\alpha_{mk} =& \sum_{j=1}^{k+1} \alpha_{m-j,n-1} \Lambda_{k+1-j} = \sum_{j=1}^{k+1} \vec\beta\cdot\vec\lambda^{(m-j)} \Lambda_{k+1-j} = \sum_{j=0}^k \Lambda_j \vec\beta\cdot \vec\lambda^{(m+j-k-1)}
\end{align}
As in the two dimensional case this defines $f(A)$ if $f$ is analytical in the eigenvalues of $A$:
\begin{align}
A^m =& \sum_{k=0}^{n-1} A^k \sum_{j=0}^k \Lambda_j \sum_{l=1}^r \lambda_l^{m+j-k-1} \sum_{p=0}^{\mu_l-1} \bar\beta_{lp} \frac{(m+j-k-1+p)!}{(m+j-k-1)!}\\
f(A) =& \sum_{k=0}^{n-1} A^k \sum_{j=0}^k \Lambda_j \sum_{l=1}^r \sum_{p=0}^{\mu_l-1} \bar\beta_{lp} \del_{\lambda_l}^p \lambda_l^{j-k-1+p} f(\lambda_l) \nonumber\\
=& \sum_{k=0}^{n-1} A^k \sum_{j=0}^k \Lambda_j \sum_{l=1}^r \sum_{p=0}^{\mu_l-1} \bar\beta_{lp} \sum_{q=0}^p \binom pq \frac{(j-k-1+p)!}{(j-k-1+q)!}\lambda_l^{j-k-1+q} f^{(q)}(\lambda_l)
\end{align}
Since $f(A)$ is linear in $A^k$ and $f^{(q)}(\lambda_l)$ we can define the tensors $\mathcal F$ and $F$, s.t.
\begin{align}
f(A) = \sum_{i=0}^{n-1} \sum_{j=1}^r \sum_{k=0}^{\mu_j-1} \mathcal F_{ij}^{(k)} A^i f^{(k)}(\lambda_j),\ \ \ \ F_{ijk}^{(l)} = \sum_{m=0}^{n-1} \mathcal F_{mk}^{(l)} (A^m)_{ij}
\end{align}
\begin{align}
\mathcal F_{kl}^{(q)} =& \del_{x_q} \del_{y_l} \sum_{j=0}^k \Lambda_j \sum_{l'=1}^r \sum_{p=0}^{\mu_{l'}-1} \bar\beta_{l'p} \sum_{q'=0}^p \binom p{q'} \frac{(j-k-1+p)!}{(j-k-1+q')!}\lambda_{l'}^{j-k-1+q'} x_{q'} y_{l'} \nonumber\\
=& \sum_{j=0}^k \Lambda_j \sum_{p=q}^{\mu_l-1} \bar\beta_{lp} \binom pq \frac{(j-k-1+p)!}{(j-k-1+q)!}\lambda_l^{j-k-1+q}
\end{align}
\subsubsection*{Sanity check for $n=2$}
\begin{itemize}
\item $\lambda_1 \neq \lambda_2\ \Rightarrow\ \mu_1 = \mu_2 = 1,\; r=2:$
\begin{align*}
\lambda_k^{(m)} =& \lambda_k^m,\ \beta_{\cdot\;0} = \frac 1{\lambda_1 - \lambda_2} \begin{pmatrix} 1\\-1 \end{pmatrix},\ \Lambda_0 = -\lambda_1\lambda_2,\ \Lambda_1 = \lambda_1 + \lambda_2\\
\mathcal F^{(0)} =& \begin{pmatrix} \Lambda_0\bar\beta_{10}/\lambda_1 & \Lambda_0\bar\beta_{20}/\lambda_2 \\ \Lambda_0\bar\beta_{10}/\lambda_1^2 + \Lambda_1\bar\beta_{10}/\lambda_1 & \Lambda_0\bar\beta_{20}/\lambda_2^2 + \Lambda_1\bar\beta_{20}/\lambda_2 \end{pmatrix} = \frac 1{\lambda_1 - \lambda_2} \begin{pmatrix} -\lambda_2 & \lambda_1 \\ 1 & -1 \end{pmatrix}\\
\Rightarrow f(A) =& \frac 1 {\lambda_1-\lambda_2}\big[ \big(f(\lambda_1) - f(\lambda_2)\big) A - \big(\lambda_2 f(\lambda_1) - \lambda_1 f(\lambda_2)\big) \mathbbm 1 \big]\ \checkmark
\end{align*}
\item $\lambda_1 = \lambda_2 = \lambda\ \Rightarrow\ \mu_1 = 2,\; r=1:$
\begin{align*}
\lambda_k^{(m)} =& \big(\lambda^m, (m+1)\lambda^m\big)_k,\ \beta_{1\;\cdot} = \frac 1\lambda \begin{pmatrix} -1\\1 \end{pmatrix},\ \Lambda_0 = -\lambda^2,\ \Lambda_1 = 2\lambda\\
\mathcal F^{(0)} =& \begin{pmatrix} \Lambda_0 \bar\beta_{10}/\lambda \\ \Lambda_0 \bar\beta_{10}/\lambda^2 + \Lambda_1 (\bar\beta_{10} + 2\bar\beta_{11})/\lambda \end{pmatrix} = \begin{pmatrix} 1 \\ 1/\lambda + 4/\lambda \end{pmatrix}\\
\Rightarrow f(A) =& \frac 1 {\lambda_1-\lambda_2}\big[ \big(f(\lambda_1) - f(\lambda_2)\big) A - \big(\lambda_2 f(\lambda_1) - \lambda_1 f(\lambda_2)\big) \mathbbm 1 \big]\ \checkmark
\end{align*}
\end{itemize}
\end{comment}

\include{matrix-functions-docu-appendix}


\end{document}

